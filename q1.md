# Question 1

## Q1.1

The shallow neural network to XOR two binary numbers:

1. First layer: Hidden layer with 2 neurons
   - Input: $x$ and $s$ (binary inputs)
   - Weights: $W_1 = \begin{bmatrix} -1 & 1 \\ 1 & -1 \end{bmatrix}$
   - Bias: $b_1 = \begin{bmatrix} 0 \\ 0 \end{bmatrix}$
   - Activation: ReLU

2. Second layer: Output layer with 1 neuron
   - Input: Output of hidden layer
   - Weights: $W_2 = \begin{bmatrix} 1 & 1 \end{bmatrix}$
   - Bias: $b_2 = \begin{bmatrix} -1 \end{bmatrix}$
   - Activation: Sigmoid

The forward pass:
- Hidden layer: $h = \text{ReLU}(W_1 \begin{bmatrix} x \\ s \end{bmatrix} + b_1)$
- Output layer: $y = \text{Sigmoid}(W_2 h + b_2)$

This network computes the XOR of inputs $x$ and $s$, so $y = x \oplus s$.

## Q1.2

To initialize the RNN at time $t = 1$ such that the output equals the input, need:

$y[1] = x[1]$

Since want $y[1] = x[1]$, and XOR function computes $y = x \oplus s$, need:

$x[1] = x[1] \oplus s[1]$

This is true when $s[1] = 0$, since $x \oplus 0 = x$ for any binary value $x$.

Therefore, should initialize $s[1] = 0$.

## Q1.3

For $t > 1$, need to choose $s[t]$ such that after $T$ time steps, get:

$y[T] = x[1] \oplus x[2] \oplus ... \oplus x[T]$

At each time step, RNN computes $y[t] = x[t] \oplus s[t]$. 

To maintain a running XOR across the sequence, should set $s[t] = y[t-1]$:

$s[t] = y[t-1] = x[t-1] \oplus s[t-1]$

With this choice:
- At $t=1$: $y[1] = x[1] \oplus s[1] = x[1] \oplus 0 = x[1]$
- At $t=2$: $y[2] = x[2] \oplus s[2] = x[2] \oplus y[1] = x[2] \oplus x[1]$
- At $t=3$: $y[3] = x[3] \oplus s[3] = x[3] \oplus y[2] = x[3] \oplus (x[2] \oplus x[1]) = x[3] \oplus x[2] \oplus x[1]$

Continuing this pattern, at time $T$:
$y[T] = x[T] \oplus s[T] = x[T] \oplus y[T-1] = x[T] \oplus x[T-1] \oplus ... \oplus x[1]$

Therefore, $s[t] = y[t-1]$ for $t > 1$ gives us the desired result.

## Q1.4

$s[t]$ is called the hidden state (or memory component) of the RNN. It represents the accumulated result of all previous XOR operations up to time $t-1$. Specifically, $s[t] = x[1] \oplus x[2] \oplus ... \oplus x[t-1]$ for $t > 1$.

## Q1.5

For time steps $t \neq 1, T$:

$y[t]$ represents the running XOR of all inputs from $x[1]$ through $x[t]$.

Specifically, $y[t] = x[1] \oplus x[2] \oplus ... \oplus x[t]$.

This means at each intermediate time step, $y[t]$ gives us the cumulative XOR result of all inputs processed up to that point.