{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n",
    "\n",
    "## Q3.1\n",
    "\n",
    "    x₁ ⊕ x₂ ⊕ x₃ ⊕ x₄ = (x₁ ⊕ x₂) ⊕ (x₃ ⊕ x₄)\n",
    "\n",
    " Thus,\n",
    "```\n",
    "Layer 1 (Input):\n",
    "      x₁    \n",
    "      x₂          z₁ = x₁ ⊕ x₂\n",
    "            XOR ------------------+\n",
    "                                  |\n",
    "      x₃                          |     \n",
    "      x₄          z₂ = x₃ ⊕ x₄    |     \n",
    "            XOR ------------------+---> z₁ ⊕ z₂ \n",
    "                                           |\n",
    "           Layer 2      Layer 3          Layer 4\n",
    "```\n",
    "- 1 input layer (4 inputs)\n",
    "- 3 hidden layers where each XOR is implemented using the structure in Q2\n",
    "- 1 output layer for the final result\n",
    "\n",
    "## Q3.2\n",
    "\n",
    "For 8 inputs, \n",
    "\n",
    "    x₁ ⊕ x₂ ⊕ x₃ ⊕ x₄ ⊕ x₅ ⊕ x₆ ⊕ x₇ ⊕ x₈ = [(x₁ ⊕ x₂) ⊕ (x₃ ⊕ x₄)] ⊕ [(x₅ ⊕ x₆) ⊕ (x₇ ⊕ x₈)]\n",
    "\n",
    "Thus,\n",
    "```\n",
    "x₁, x₂   \n",
    "         z₁ = x₁ ⊕ x₂\n",
    "x₃, x₄            \n",
    "         z₂ = x₃ ⊕ x₄     z₅ = z₁ ⊕ z₂\n",
    "                                         z₅ ⊕ z₆\n",
    "x₅, x₆                                  \n",
    "         z₃ = x₅ ⊕ x₆     z₆ = z₃ ⊕ z₄    \n",
    "x₇, x₈                                    \n",
    "         z₄ = x₇ ⊕ x₈                 \n",
    "\n",
    "Layer 1      Layer 2         Layer 3     Layer 4\n",
    "```\n",
    "\n",
    "- First layer to compute pairwise XORs (x₁⊕x₂, x₃⊕x₄, x₅⊕x₆, x₇⊕x₈)\n",
    "- Second layer to combine pairs (z₁⊕z₂, z₃⊕z₄)\n",
    "- Third layer to compute z₅, z₆\n",
    "- Final layer to combine z₅⊕z₆\n",
    "\n",
    "-> 4 layers\n",
    "\n",
    "## Q3.3\n",
    "\n",
    "- For N=2 (K=1): need 1 layer\n",
    "- For N=4 (K=2): need 3 layers\n",
    "- For N=8 (K=3): need 4 layers\n",
    "\n",
    "For N = 2ᴷ inputs:\n",
    "\n",
    "- First layer handles pairs\n",
    "- Each subsequent layer combines results from previous layer\n",
    "- Process continues until getting final output\n",
    "\n",
    "Thus, for input size N = 2ᴷ, the number of hidden layers is K + 1.\n",
    "\n",
    "## Q3.4\n",
    "\n",
    "Neurons by layer:\n",
    "\n",
    "- N = 8 (K = 3):\n",
    "    - Input:    8 inputs   (not neurons)\n",
    "    - Layer 1:  4 neuron   (8/2 pairs)\n",
    "    - Layer 2:  2 neuron   (4/2 pairs)\n",
    "    - Layer 3:  1 neuron   (2/2 pairs)\n",
    "    - Layer 4:  1 neuron   (final output)\n",
    "\n",
    "- N = 4 (K = 2):\n",
    "    - Input:    4 inputs\n",
    "    - Layer 1:  2 neuron\n",
    "    - Layer 2:  1 neuron\n",
    "    - Layer 3:  1 neuron\n",
    "\n",
    "- N = 2ᴷ:\n",
    "\n",
    "    - Layer 1:  N/2 neurons\n",
    "    - Layer 2:  N/4 neurons\n",
    "    - Layer 3:  N/8 neurons\n",
    "    - ...until  reaching 1 neuron\n",
    "\n",
    "```\n",
    "Total neurons = N/2 + N/4 + N/8 + ... + 1\n",
    "              = 2ᴷ⁻¹ + 2ᴷ⁻² + 2ᴷ⁻³ + ... + 1\n",
    "              = 2ᴷ - 1 (using 1.14)\n",
    "```\n",
    "\n",
    "## Q3.5\n",
    "\n",
    "Comparison:\n",
    "\n",
    "Deep Network (our design):\n",
    "\n",
    "- Total neurons = N-1 = 2ᴷ-1\n",
    "\n",
    "-> Deep network scales linearly (N-1)\n",
    "\n",
    "Shallow Network (one hidden layer):\n",
    "\n",
    "- Total neurons = 2ᴷ⁻¹ (as stated in 1.11)\n",
    "- For N = 2ᴷ inputs, needs 2ᴺ⁻¹ neurons in hidden layer\n",
    "\n",
    "-> Shallow network scales exponentially (2ᴷ⁻¹)\n",
    "\n",
    "Clearly shows deep networks are more efficient by breaking down the problem hierarchically and solving the same problem with far fewer total neurons.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
